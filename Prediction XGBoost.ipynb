{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unifying names \n",
    "data=pd.read_csv(\"train.csv\")\n",
    "data = data.rename(columns={\"pickup_BoroCode\":\"pickup_boro_code\",\"pickup_NTACode\":\"pickup_nta_code\",\"dropoff_BoroCode\":\"dropoff_boro_code\",\"dropoff_NTACode\":\"dropoff_nta_code\", \"pickup_doy\":\"pickup_day\"})\n",
    "data=data[data[\"length_time\"]<=4236]\n",
    "data=data.loc[data[\"length_time\"]>=60] \n",
    "data=data.loc[data[\"trip_distance\"]>=0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>response</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_month</th>\n",
       "      <th>pickup_week</th>\n",
       "      <th>pickup_day</th>\n",
       "      <th>pickup_wday</th>\n",
       "      <th>length_time</th>\n",
       "      <th>pickup_boro_code</th>\n",
       "      <th>pickup_nta_code</th>\n",
       "      <th>dropoff_boro_code</th>\n",
       "      <th>dropoff_nta_code</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>132</td>\n",
       "      <td>4</td>\n",
       "      <td>520</td>\n",
       "      <td>1</td>\n",
       "      <td>MN15</td>\n",
       "      <td>1</td>\n",
       "      <td>MN19</td>\n",
       "      <td>-73.983009</td>\n",
       "      <td>40.766602</td>\n",
       "      <td>-73.967972</td>\n",
       "      <td>40.760677</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>7.0</td>\n",
       "      <td>MN15-MN19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.95</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>127</td>\n",
       "      <td>6</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "      <td>MN21</td>\n",
       "      <td>1</td>\n",
       "      <td>MN24</td>\n",
       "      <td>-73.989510</td>\n",
       "      <td>40.734470</td>\n",
       "      <td>-73.997185</td>\n",
       "      <td>40.717976</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MN21-MN24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.46</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>132</td>\n",
       "      <td>4</td>\n",
       "      <td>1016</td>\n",
       "      <td>1</td>\n",
       "      <td>MN25</td>\n",
       "      <td>1</td>\n",
       "      <td>MN27</td>\n",
       "      <td>-74.012741</td>\n",
       "      <td>40.702229</td>\n",
       "      <td>-73.998878</td>\n",
       "      <td>40.713711</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.14</td>\n",
       "      <td>11.5</td>\n",
       "      <td>MN25-MN27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.66</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>134</td>\n",
       "      <td>6</td>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "      <td>MN99</td>\n",
       "      <td>1</td>\n",
       "      <td>MN20</td>\n",
       "      <td>-73.970909</td>\n",
       "      <td>40.767231</td>\n",
       "      <td>-73.979507</td>\n",
       "      <td>40.752331</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.28</td>\n",
       "      <td>7.5</td>\n",
       "      <td>MN99-MN20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>501</td>\n",
       "      <td>1</td>\n",
       "      <td>MN20</td>\n",
       "      <td>1</td>\n",
       "      <td>MN22</td>\n",
       "      <td>-73.973869</td>\n",
       "      <td>40.747925</td>\n",
       "      <td>-73.986618</td>\n",
       "      <td>40.730328</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.40</td>\n",
       "      <td>7.5</td>\n",
       "      <td>MN20-MN22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343741</th>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>145</td>\n",
       "      <td>3</td>\n",
       "      <td>740</td>\n",
       "      <td>1</td>\n",
       "      <td>MN12</td>\n",
       "      <td>1</td>\n",
       "      <td>MN36</td>\n",
       "      <td>-73.978676</td>\n",
       "      <td>40.783512</td>\n",
       "      <td>-73.938370</td>\n",
       "      <td>40.850533</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.84</td>\n",
       "      <td>18.5</td>\n",
       "      <td>MN12-MN36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343742</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>141</td>\n",
       "      <td>6</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>MN14</td>\n",
       "      <td>1</td>\n",
       "      <td>MN12</td>\n",
       "      <td>-73.982048</td>\n",
       "      <td>40.775452</td>\n",
       "      <td>-73.976860</td>\n",
       "      <td>40.783520</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.5</td>\n",
       "      <td>MN14-MN12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343743</th>\n",
       "      <td>1</td>\n",
       "      <td>2.35</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>132</td>\n",
       "      <td>4</td>\n",
       "      <td>764</td>\n",
       "      <td>1</td>\n",
       "      <td>MN20</td>\n",
       "      <td>1</td>\n",
       "      <td>MN22</td>\n",
       "      <td>-73.974472</td>\n",
       "      <td>40.747253</td>\n",
       "      <td>-73.983070</td>\n",
       "      <td>40.726955</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.70</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MN20-MN22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343744</th>\n",
       "      <td>1</td>\n",
       "      <td>2.65</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>955</td>\n",
       "      <td>1</td>\n",
       "      <td>MN13</td>\n",
       "      <td>1</td>\n",
       "      <td>MN27</td>\n",
       "      <td>-73.993607</td>\n",
       "      <td>40.745293</td>\n",
       "      <td>-73.987350</td>\n",
       "      <td>40.722256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>12.0</td>\n",
       "      <td>MN13-MN27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343745</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>135</td>\n",
       "      <td>7</td>\n",
       "      <td>440</td>\n",
       "      <td>1</td>\n",
       "      <td>MN31</td>\n",
       "      <td>1</td>\n",
       "      <td>MN12</td>\n",
       "      <td>-73.949684</td>\n",
       "      <td>40.770271</td>\n",
       "      <td>-73.978127</td>\n",
       "      <td>40.783112</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.94</td>\n",
       "      <td>8.0</td>\n",
       "      <td>MN31-MN12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341009 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        weight  response  pickup_hour  pickup_month  pickup_week  pickup_day   \n",
       "0            1      1.75           18             5           19         132  \\\n",
       "1            1      2.95           18             5           19         127   \n",
       "2            1      2.46            7             5           19         132   \n",
       "3            1      1.66           11             5           20         134   \n",
       "4            1      1.75           20             5           19         128   \n",
       "...        ...       ...          ...           ...          ...         ...   \n",
       "343741       1      2.00           20             5           21         145   \n",
       "343742       1      1.00           23             5           21         141   \n",
       "343743       1      2.35           19             5           19         132   \n",
       "343744       1      2.65           21             5           20         140   \n",
       "343745       1      1.00            7             5           20         135   \n",
       "\n",
       "        pickup_wday  length_time  pickup_boro_code pickup_nta_code   \n",
       "0                 4          520                 1            MN15  \\\n",
       "1                 6          824                 1            MN21   \n",
       "2                 4         1016                 1            MN25   \n",
       "3                 6          550                 1            MN99   \n",
       "4                 7          501                 1            MN20   \n",
       "...             ...          ...               ...             ...   \n",
       "343741            3          740                 1            MN12   \n",
       "343742            6          193                 1            MN14   \n",
       "343743            4          764                 1            MN20   \n",
       "343744            5          955                 1            MN13   \n",
       "343745            7          440                 1            MN31   \n",
       "\n",
       "        dropoff_boro_code dropoff_nta_code  pickup_longitude  pickup_latitude   \n",
       "0                       1             MN19        -73.983009        40.766602  \\\n",
       "1                       1             MN24        -73.989510        40.734470   \n",
       "2                       1             MN27        -74.012741        40.702229   \n",
       "3                       1             MN20        -73.970909        40.767231   \n",
       "4                       1             MN22        -73.973869        40.747925   \n",
       "...                   ...              ...               ...              ...   \n",
       "343741                  1             MN36        -73.978676        40.783512   \n",
       "343742                  1             MN12        -73.982048        40.775452   \n",
       "343743                  1             MN22        -73.974472        40.747253   \n",
       "343744                  1             MN27        -73.993607        40.745293   \n",
       "343745                  1             MN12        -73.949684        40.770271   \n",
       "\n",
       "        dropoff_longitude  dropoff_latitude  vendor_id  passenger_count   \n",
       "0              -73.967972         40.760677          1                1  \\\n",
       "1              -73.997185         40.717976          1                1   \n",
       "2              -73.998878         40.713711          2                1   \n",
       "3              -73.979507         40.752331          2                1   \n",
       "4              -73.986618         40.730328          1                1   \n",
       "...                   ...               ...        ...              ...   \n",
       "343741         -73.938370         40.850533          2                1   \n",
       "343742         -73.976860         40.783520          2                6   \n",
       "343743         -73.983070         40.726955          1                1   \n",
       "343744         -73.987350         40.722256          1                1   \n",
       "343745         -73.978127         40.783112          2                2   \n",
       "\n",
       "        trip_distance  fare_amount       pair  \n",
       "0                0.90          7.0  MN15-MN19  \n",
       "1                1.40         10.0  MN21-MN24  \n",
       "2                1.14         11.5  MN25-MN27  \n",
       "3                1.28          7.5  MN99-MN20  \n",
       "4                1.40          7.5  MN20-MN22  \n",
       "...               ...          ...        ...  \n",
       "343741           5.84         18.5  MN12-MN36  \n",
       "343742           0.70          4.5  MN14-MN12  \n",
       "343743           1.70         10.0  MN20-MN22  \n",
       "343744           2.20         12.0  MN13-MN27  \n",
       "343745           1.94          8.0  MN31-MN12  \n",
       "\n",
       "[341009 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data[\"response\"]\n",
    "X=data.drop([\"response\",\"pair\"], axis=1)\n",
    "X['vendor_id']=X[\"vendor_id\"].map(str)\n",
    "X['pickup_boro_code']=X[\"pickup_boro_code\"].map(str)\n",
    "X['dropoff_boro_code']=X[\"dropoff_boro_code\"].map(str)\n",
    "X=pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error\n",
    "\n",
    "def evaluate_estimator(estimator, X, y): \n",
    "    # Make predictions\n",
    "    y_pred = estimator.predict(X)\n",
    "    \n",
    "    \n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    \n",
    "    # Create a dictionary to hold the performance metrics\n",
    "    metrics = {\n",
    "        'MAE': mae\n",
    "    }\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_residuals(model, X, y):\n",
    "    \"\"\"\n",
    "    Plot residuals of a model.\n",
    "    \n",
    "    Parameters:\n",
    "        model: Fitted regression model (e.g., from scikit-learn)\n",
    "        X: Independent variables (features)\n",
    "        y: Observed values\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Make predictions using the model\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Compute residuals\n",
    "    residuals = y - y_pred\n",
    "\n",
    "    # Plot residuals against predicted values\n",
    "    plt.scatter(y_pred, residuals)\n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residual Plot')\n",
    "    plt.axhline(y=0, color='r', linestyle='--')  # Add a horizontal line at y=0\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.693 GB of training data: 3.100 s\n",
      "Binning 0.077 GB of validation data: 0.043 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/1000] 1 tree, 31 leaves, max depth = 7, train loss: 1.27378, val loss: 1.28731, in 0.213s\n",
      "[2/1000] 1 tree, 31 leaves, max depth = 8, train loss: 1.18760, val loss: 1.19968, in 0.173s\n",
      "[3/1000] 1 tree, 31 leaves, max depth = 9, train loss: 1.11322, val loss: 1.12384, in 0.188s\n",
      "[4/1000] 1 tree, 31 leaves, max depth = 10, train loss: 1.04657, val loss: 1.05584, in 0.176s\n",
      "[5/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.98650, val loss: 0.99480, in 0.165s\n",
      "[6/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.93521, val loss: 0.94290, in 0.169s\n",
      "[7/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.89183, val loss: 0.89907, in 0.178s\n",
      "[8/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.85621, val loss: 0.86343, in 0.183s\n",
      "[9/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.82232, val loss: 0.82932, in 0.175s\n",
      "[10/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.79276, val loss: 0.79943, in 0.162s\n",
      "[11/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.76837, val loss: 0.77447, in 0.177s\n",
      "[12/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.74771, val loss: 0.75331, in 0.173s\n",
      "[13/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.73061, val loss: 0.73618, in 0.182s\n",
      "[14/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.71350, val loss: 0.71860, in 0.187s\n",
      "[15/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.69906, val loss: 0.70365, in 0.174s\n",
      "[16/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.68590, val loss: 0.68994, in 0.173s\n",
      "[17/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.67558, val loss: 0.67940, in 0.182s\n",
      "[18/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.66574, val loss: 0.66952, in 0.175s\n",
      "[19/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.65773, val loss: 0.66147, in 0.176s\n",
      "[20/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.64730, val loss: 0.65087, in 0.180s\n",
      "[21/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.64065, val loss: 0.64426, in 0.183s\n",
      "[22/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.63297, val loss: 0.63638, in 0.292s\n",
      "[23/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.62628, val loss: 0.62957, in 0.184s\n",
      "[24/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.61922, val loss: 0.62240, in 0.185s\n",
      "[25/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.61296, val loss: 0.61611, in 0.180s\n",
      "[26/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.60745, val loss: 0.61061, in 0.164s\n",
      "[27/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.60258, val loss: 0.60579, in 0.173s\n",
      "[28/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.59819, val loss: 0.60149, in 0.164s\n",
      "[29/1000] 1 tree, 31 leaves, max depth = 7, train loss: 0.59569, val loss: 0.59898, in 0.171s\n",
      "[30/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.59318, val loss: 0.59651, in 0.167s\n",
      "[31/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.59101, val loss: 0.59441, in 0.177s\n",
      "[32/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.58888, val loss: 0.59229, in 0.179s\n",
      "[33/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.58679, val loss: 0.59021, in 0.181s\n",
      "[34/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58497, val loss: 0.58844, in 0.171s\n",
      "[35/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.58335, val loss: 0.58686, in 0.174s\n",
      "[36/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.58170, val loss: 0.58518, in 0.182s\n",
      "[37/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.58038, val loss: 0.58388, in 0.179s\n",
      "[38/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57776, val loss: 0.58129, in 0.186s\n",
      "[39/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.57655, val loss: 0.58011, in 0.169s\n",
      "[40/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57570, val loss: 0.57926, in 0.172s\n",
      "[41/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57476, val loss: 0.57836, in 0.209s\n",
      "[42/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.57379, val loss: 0.57741, in 0.214s\n",
      "[43/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57286, val loss: 0.57642, in 0.261s\n",
      "[44/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57213, val loss: 0.57570, in 0.209s\n",
      "[45/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57173, val loss: 0.57534, in 0.174s\n",
      "[46/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.57052, val loss: 0.57407, in 0.194s\n",
      "[47/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56984, val loss: 0.57341, in 0.198s\n",
      "[48/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56953, val loss: 0.57306, in 0.198s\n",
      "[49/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56919, val loss: 0.57271, in 0.189s\n",
      "[50/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56884, val loss: 0.57233, in 0.195s\n",
      "[51/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56842, val loss: 0.57188, in 0.212s\n",
      "[52/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56807, val loss: 0.57151, in 0.176s\n",
      "[53/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.56771, val loss: 0.57113, in 0.170s\n",
      "[54/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56727, val loss: 0.57067, in 0.157s\n",
      "[55/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56697, val loss: 0.57036, in 0.168s\n",
      "[56/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56659, val loss: 0.56995, in 0.182s\n",
      "[57/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56622, val loss: 0.56957, in 0.185s\n",
      "[58/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56597, val loss: 0.56931, in 0.174s\n",
      "[59/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56565, val loss: 0.56898, in 0.180s\n",
      "[60/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56549, val loss: 0.56882, in 0.160s\n",
      "[61/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56535, val loss: 0.56867, in 0.157s\n",
      "[62/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56516, val loss: 0.56847, in 0.180s\n",
      "[63/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56501, val loss: 0.56831, in 0.167s\n",
      "[64/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56478, val loss: 0.56808, in 0.164s\n",
      "[65/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56459, val loss: 0.56788, in 0.208s\n",
      "[66/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56408, val loss: 0.56735, in 0.178s\n",
      "[67/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56393, val loss: 0.56720, in 0.174s\n",
      "[68/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56378, val loss: 0.56703, in 0.197s\n",
      "[69/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56363, val loss: 0.56688, in 0.174s\n",
      "[70/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56334, val loss: 0.56654, in 0.175s\n",
      "[71/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56287, val loss: 0.56606, in 0.192s\n",
      "[72/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56273, val loss: 0.56592, in 0.191s\n",
      "[73/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56260, val loss: 0.56578, in 0.176s\n",
      "[74/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56236, val loss: 0.56555, in 0.163s\n",
      "[75/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56215, val loss: 0.56534, in 0.159s\n",
      "[76/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.56176, val loss: 0.56496, in 0.169s\n",
      "[77/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56159, val loss: 0.56479, in 0.174s\n",
      "[78/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56146, val loss: 0.56466, in 0.171s\n",
      "[79/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.56128, val loss: 0.56447, in 0.177s\n",
      "[80/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.56109, val loss: 0.56427, in 0.171s\n",
      "[81/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.56105, val loss: 0.56423, in 0.164s\n",
      "[82/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56099, val loss: 0.56416, in 0.168s\n",
      "[83/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56089, val loss: 0.56406, in 0.172s\n",
      "[84/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56086, val loss: 0.56401, in 0.166s\n",
      "[85/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.56068, val loss: 0.56384, in 0.177s\n",
      "[86/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.56065, val loss: 0.56381, in 0.169s\n",
      "[87/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56028, val loss: 0.56344, in 0.161s\n",
      "[88/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.56012, val loss: 0.56325, in 0.171s\n",
      "[89/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.56000, val loss: 0.56313, in 0.184s\n",
      "[90/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55996, val loss: 0.56309, in 0.172s\n",
      "[91/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55988, val loss: 0.56301, in 0.174s\n",
      "[92/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55981, val loss: 0.56294, in 0.168s\n",
      "[93/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55968, val loss: 0.56284, in 0.168s\n",
      "[94/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55960, val loss: 0.56276, in 0.167s\n",
      "[95/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55952, val loss: 0.56268, in 0.180s\n",
      "[96/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55951, val loss: 0.56267, in 0.156s\n",
      "[97/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55950, val loss: 0.56266, in 0.152s\n",
      "[98/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55913, val loss: 0.56232, in 0.153s\n",
      "[99/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55912, val loss: 0.56232, in 0.162s\n",
      "[100/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55892, val loss: 0.56215, in 0.163s\n",
      "[101/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55890, val loss: 0.56212, in 0.142s\n",
      "[102/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55877, val loss: 0.56202, in 0.167s\n",
      "[103/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55877, val loss: 0.56201, in 0.145s\n",
      "[104/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55844, val loss: 0.56171, in 0.163s\n",
      "[105/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55843, val loss: 0.56170, in 0.146s\n",
      "[106/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55840, val loss: 0.56167, in 0.170s\n",
      "[107/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55839, val loss: 0.56166, in 0.138s\n",
      "[108/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55839, val loss: 0.56165, in 0.195s\n",
      "[109/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55828, val loss: 0.56154, in 0.162s\n",
      "[110/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55807, val loss: 0.56135, in 0.166s\n",
      "[111/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55795, val loss: 0.56124, in 0.206s\n",
      "[112/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55794, val loss: 0.56123, in 0.184s\n",
      "[113/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55785, val loss: 0.56114, in 0.210s\n",
      "[114/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55784, val loss: 0.56113, in 0.169s\n",
      "[115/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55783, val loss: 0.56112, in 0.146s\n",
      "[116/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55775, val loss: 0.56105, in 0.167s\n",
      "[117/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55763, val loss: 0.56092, in 0.208s\n",
      "[118/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55751, val loss: 0.56080, in 0.157s\n",
      "[119/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55751, val loss: 0.56079, in 0.178s\n",
      "[120/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55737, val loss: 0.56069, in 0.177s\n",
      "[121/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55736, val loss: 0.56068, in 0.146s\n",
      "[122/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55724, val loss: 0.56056, in 0.221s\n",
      "[123/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55706, val loss: 0.56040, in 0.207s\n",
      "[124/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55703, val loss: 0.56035, in 0.167s\n",
      "[125/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55691, val loss: 0.56023, in 0.158s\n",
      "[126/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55681, val loss: 0.56013, in 0.186s\n",
      "[127/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55679, val loss: 0.56010, in 0.184s\n",
      "[128/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55674, val loss: 0.56006, in 0.180s\n",
      "[129/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55666, val loss: 0.55997, in 0.171s\n",
      "[130/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55662, val loss: 0.55993, in 0.177s\n",
      "[131/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55661, val loss: 0.55992, in 0.157s\n",
      "[132/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55659, val loss: 0.55990, in 0.163s\n",
      "[133/1000] 1 tree, 31 leaves, max depth = 17, train loss: 0.55652, val loss: 0.55985, in 0.165s\n",
      "[134/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55648, val loss: 0.55981, in 0.205s\n",
      "[135/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55643, val loss: 0.55976, in 0.199s\n",
      "[136/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55642, val loss: 0.55974, in 0.177s\n",
      "[137/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55642, val loss: 0.55974, in 0.144s\n",
      "[138/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55638, val loss: 0.55971, in 0.162s\n",
      "[139/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55634, val loss: 0.55966, in 0.167s\n",
      "[140/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55629, val loss: 0.55961, in 0.173s\n",
      "[141/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55628, val loss: 0.55961, in 0.131s\n",
      "[142/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55624, val loss: 0.55957, in 0.164s\n",
      "[143/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55620, val loss: 0.55953, in 0.166s\n",
      "[144/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55614, val loss: 0.55947, in 0.163s\n",
      "[145/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55595, val loss: 0.55931, in 0.162s\n",
      "[146/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55592, val loss: 0.55928, in 0.153s\n",
      "[147/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55577, val loss: 0.55915, in 0.164s\n",
      "[148/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55570, val loss: 0.55908, in 0.156s\n",
      "[149/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55567, val loss: 0.55904, in 0.167s\n",
      "[150/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55562, val loss: 0.55899, in 0.165s\n",
      "[151/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55558, val loss: 0.55894, in 0.158s\n",
      "[152/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55538, val loss: 0.55879, in 0.148s\n",
      "[153/1000] 1 tree, 31 leaves, max depth = 17, train loss: 0.55525, val loss: 0.55866, in 0.165s\n",
      "[154/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.55514, val loss: 0.55858, in 0.145s\n",
      "[155/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55506, val loss: 0.55851, in 0.158s\n",
      "[156/1000] 1 tree, 31 leaves, max depth = 19, train loss: 0.55503, val loss: 0.55847, in 0.145s\n",
      "[157/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55495, val loss: 0.55842, in 0.144s\n",
      "[158/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55487, val loss: 0.55838, in 0.142s\n",
      "[159/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55486, val loss: 0.55837, in 0.201s\n",
      "[160/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55481, val loss: 0.55832, in 0.154s\n",
      "[161/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55480, val loss: 0.55831, in 0.178s\n",
      "[162/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55470, val loss: 0.55823, in 0.148s\n",
      "[163/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55465, val loss: 0.55818, in 0.154s\n",
      "[164/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55463, val loss: 0.55816, in 0.145s\n",
      "[165/1000] 1 tree, 31 leaves, max depth = 18, train loss: 0.55449, val loss: 0.55804, in 0.155s\n",
      "[166/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.55429, val loss: 0.55786, in 0.150s\n",
      "[167/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55410, val loss: 0.55770, in 0.133s\n",
      "[168/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55399, val loss: 0.55763, in 0.137s\n",
      "[169/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55382, val loss: 0.55750, in 0.147s\n",
      "[170/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.55376, val loss: 0.55745, in 0.164s\n",
      "[171/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.55360, val loss: 0.55732, in 0.143s\n",
      "[172/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55347, val loss: 0.55722, in 0.158s\n",
      "[173/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55328, val loss: 0.55705, in 0.148s\n",
      "[174/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55321, val loss: 0.55701, in 0.147s\n",
      "[175/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55318, val loss: 0.55700, in 0.136s\n",
      "[176/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55317, val loss: 0.55699, in 0.127s\n",
      "[177/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55304, val loss: 0.55691, in 0.148s\n",
      "[178/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55304, val loss: 0.55691, in 0.146s\n",
      "[179/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55296, val loss: 0.55685, in 0.139s\n",
      "[180/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55295, val loss: 0.55684, in 0.143s\n",
      "[181/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55277, val loss: 0.55668, in 0.188s\n",
      "[182/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55273, val loss: 0.55664, in 0.159s\n",
      "[183/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55263, val loss: 0.55655, in 0.135s\n",
      "[184/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55252, val loss: 0.55644, in 0.145s\n",
      "[185/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55251, val loss: 0.55643, in 0.143s\n",
      "[186/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55248, val loss: 0.55640, in 0.135s\n",
      "[187/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55242, val loss: 0.55633, in 0.146s\n",
      "[188/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55239, val loss: 0.55630, in 0.160s\n",
      "[189/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55230, val loss: 0.55622, in 0.132s\n",
      "[190/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55229, val loss: 0.55621, in 0.132s\n",
      "[191/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.55220, val loss: 0.55613, in 0.156s\n",
      "[192/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55214, val loss: 0.55607, in 0.147s\n",
      "[193/1000] 1 tree, 31 leaves, max depth = 18, train loss: 0.55207, val loss: 0.55603, in 0.148s\n",
      "[194/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55202, val loss: 0.55598, in 0.136s\n",
      "[195/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55195, val loss: 0.55591, in 0.148s\n",
      "[196/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55194, val loss: 0.55591, in 0.156s\n",
      "[197/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55172, val loss: 0.55571, in 0.196s\n",
      "[198/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55171, val loss: 0.55570, in 0.262s\n",
      "[199/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55167, val loss: 0.55565, in 0.160s\n",
      "[200/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55163, val loss: 0.55561, in 0.164s\n",
      "[201/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55159, val loss: 0.55558, in 0.173s\n",
      "[202/1000] 1 tree, 31 leaves, max depth = 17, train loss: 0.55143, val loss: 0.55545, in 0.162s\n",
      "[203/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55139, val loss: 0.55542, in 0.159s\n",
      "[204/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55137, val loss: 0.55541, in 0.158s\n",
      "[205/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.55125, val loss: 0.55530, in 0.148s\n",
      "[206/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55122, val loss: 0.55526, in 0.168s\n",
      "[207/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55118, val loss: 0.55524, in 0.166s\n",
      "[208/1000] 1 tree, 31 leaves, max depth = 18, train loss: 0.55105, val loss: 0.55512, in 0.146s\n",
      "[209/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55102, val loss: 0.55509, in 0.152s\n",
      "[210/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55098, val loss: 0.55507, in 0.178s\n",
      "[211/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55095, val loss: 0.55505, in 0.150s\n",
      "[212/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55090, val loss: 0.55502, in 0.147s\n",
      "[213/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55077, val loss: 0.55492, in 0.141s\n",
      "[214/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55074, val loss: 0.55490, in 0.149s\n",
      "[215/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55070, val loss: 0.55489, in 0.151s\n",
      "[216/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55055, val loss: 0.55476, in 0.151s\n",
      "[217/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55046, val loss: 0.55467, in 0.154s\n",
      "[218/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55041, val loss: 0.55463, in 0.152s\n",
      "[219/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.55041, val loss: 0.55463, in 0.199s\n",
      "[220/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55038, val loss: 0.55460, in 0.167s\n",
      "[221/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55038, val loss: 0.55460, in 0.141s\n",
      "[222/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.55036, val loss: 0.55458, in 0.174s\n",
      "[223/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55035, val loss: 0.55457, in 0.165s\n",
      "[224/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55033, val loss: 0.55455, in 0.136s\n",
      "[225/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.55027, val loss: 0.55450, in 0.151s\n",
      "[226/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55023, val loss: 0.55446, in 0.153s\n",
      "[227/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55013, val loss: 0.55440, in 0.144s\n",
      "[228/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.55013, val loss: 0.55440, in 0.135s\n",
      "[229/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.55008, val loss: 0.55436, in 0.144s\n",
      "[230/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.55005, val loss: 0.55434, in 0.152s\n",
      "[231/1000] 1 tree, 31 leaves, max depth = 18, train loss: 0.55001, val loss: 0.55429, in 0.167s\n",
      "[232/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55001, val loss: 0.55428, in 0.149s\n",
      "[233/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55000, val loss: 0.55428, in 0.141s\n",
      "[234/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.55000, val loss: 0.55427, in 0.122s\n",
      "[235/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54999, val loss: 0.55426, in 0.131s\n",
      "[236/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54999, val loss: 0.55426, in 0.130s\n",
      "[237/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54998, val loss: 0.55425, in 0.130s\n",
      "[238/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54998, val loss: 0.55425, in 0.126s\n",
      "[239/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54997, val loss: 0.55424, in 0.134s\n",
      "[240/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54997, val loss: 0.55424, in 0.135s\n",
      "[241/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54997, val loss: 0.55423, in 0.130s\n",
      "[242/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54996, val loss: 0.55423, in 0.130s\n",
      "[243/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54996, val loss: 0.55423, in 0.123s\n",
      "[244/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54996, val loss: 0.55422, in 0.128s\n",
      "[245/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54995, val loss: 0.55421, in 0.153s\n",
      "[246/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54980, val loss: 0.55398, in 0.133s\n",
      "[247/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54970, val loss: 0.55390, in 0.133s\n",
      "[248/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54964, val loss: 0.55383, in 0.149s\n",
      "[249/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54963, val loss: 0.55381, in 0.157s\n",
      "[250/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54962, val loss: 0.55381, in 0.205s\n",
      "[251/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54961, val loss: 0.55379, in 0.171s\n",
      "[252/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54961, val loss: 0.55379, in 0.133s\n",
      "[253/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54959, val loss: 0.55377, in 0.151s\n",
      "[254/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54957, val loss: 0.55375, in 0.148s\n",
      "[255/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54954, val loss: 0.55372, in 0.185s\n",
      "[256/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54953, val loss: 0.55371, in 0.199s\n",
      "[257/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54953, val loss: 0.55371, in 0.140s\n",
      "[258/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54952, val loss: 0.55371, in 0.152s\n",
      "[259/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54952, val loss: 0.55370, in 0.140s\n",
      "[260/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54951, val loss: 0.55370, in 0.149s\n",
      "[261/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54951, val loss: 0.55369, in 0.178s\n",
      "[262/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54949, val loss: 0.55368, in 0.139s\n",
      "[263/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54943, val loss: 0.55363, in 0.137s\n",
      "[264/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54933, val loss: 0.55349, in 0.128s\n",
      "[265/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54927, val loss: 0.55343, in 0.140s\n",
      "[266/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54922, val loss: 0.55339, in 0.120s\n",
      "[267/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54916, val loss: 0.55335, in 0.165s\n",
      "[268/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54914, val loss: 0.55333, in 0.196s\n",
      "[269/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54911, val loss: 0.55329, in 0.208s\n",
      "[270/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54910, val loss: 0.55328, in 0.176s\n",
      "[271/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54908, val loss: 0.55327, in 0.152s\n",
      "[272/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54908, val loss: 0.55327, in 0.174s\n",
      "[273/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54907, val loss: 0.55326, in 0.181s\n",
      "[274/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54904, val loss: 0.55324, in 0.153s\n",
      "[275/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54900, val loss: 0.55322, in 0.126s\n",
      "[276/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54893, val loss: 0.55312, in 0.148s\n",
      "[277/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54887, val loss: 0.55312, in 0.166s\n",
      "[278/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54886, val loss: 0.55311, in 0.177s\n",
      "[279/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54886, val loss: 0.55311, in 0.170s\n",
      "[280/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54885, val loss: 0.55311, in 0.145s\n",
      "[281/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54885, val loss: 0.55310, in 0.137s\n",
      "[282/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54885, val loss: 0.55310, in 0.133s\n",
      "[283/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54884, val loss: 0.55310, in 0.143s\n",
      "[284/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54881, val loss: 0.55307, in 0.141s\n",
      "[285/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54880, val loss: 0.55306, in 0.150s\n",
      "[286/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54877, val loss: 0.55303, in 0.151s\n",
      "[287/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54872, val loss: 0.55297, in 0.152s\n",
      "[288/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54871, val loss: 0.55296, in 0.148s\n",
      "[289/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54871, val loss: 0.55296, in 0.174s\n",
      "[290/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54870, val loss: 0.55295, in 0.219s\n",
      "[291/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54869, val loss: 0.55295, in 0.173s\n",
      "[292/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54869, val loss: 0.55295, in 0.146s\n",
      "[293/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54869, val loss: 0.55295, in 0.133s\n",
      "[294/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54869, val loss: 0.55295, in 0.143s\n",
      "[295/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54869, val loss: 0.55294, in 0.145s\n",
      "[296/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54869, val loss: 0.55294, in 0.127s\n",
      "[297/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54868, val loss: 0.55293, in 0.134s\n",
      "[298/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54867, val loss: 0.55292, in 0.209s\n",
      "[299/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54867, val loss: 0.55292, in 0.148s\n",
      "[300/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54866, val loss: 0.55291, in 0.203s\n",
      "[301/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54863, val loss: 0.55289, in 0.184s\n",
      "[302/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54863, val loss: 0.55289, in 0.160s\n",
      "[303/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54862, val loss: 0.55288, in 0.149s\n",
      "[304/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54862, val loss: 0.55287, in 0.136s\n",
      "[305/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54861, val loss: 0.55287, in 0.149s\n",
      "[306/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54855, val loss: 0.55281, in 0.175s\n",
      "[307/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54855, val loss: 0.55281, in 0.148s\n",
      "[308/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54855, val loss: 0.55281, in 0.124s\n",
      "[309/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54854, val loss: 0.55280, in 0.158s\n",
      "[310/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54853, val loss: 0.55279, in 0.149s\n",
      "[311/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54847, val loss: 0.55274, in 0.134s\n",
      "[312/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54846, val loss: 0.55273, in 0.142s\n",
      "[313/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54842, val loss: 0.55269, in 0.137s\n",
      "[314/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54842, val loss: 0.55268, in 0.132s\n",
      "[315/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54841, val loss: 0.55268, in 0.139s\n",
      "[316/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54835, val loss: 0.55263, in 0.132s\n",
      "[317/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54829, val loss: 0.55257, in 0.134s\n",
      "[318/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54825, val loss: 0.55254, in 0.135s\n",
      "[319/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54824, val loss: 0.55253, in 0.176s\n",
      "[320/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54822, val loss: 0.55251, in 0.145s\n",
      "[321/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54821, val loss: 0.55251, in 0.153s\n",
      "[322/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54818, val loss: 0.55249, in 0.131s\n",
      "[323/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54817, val loss: 0.55248, in 0.149s\n",
      "[324/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54816, val loss: 0.55248, in 0.127s\n",
      "[325/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54815, val loss: 0.55247, in 0.146s\n",
      "[326/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54815, val loss: 0.55247, in 0.140s\n",
      "[327/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54814, val loss: 0.55246, in 0.148s\n",
      "[328/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54814, val loss: 0.55246, in 0.142s\n",
      "[329/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54814, val loss: 0.55246, in 0.162s\n",
      "[330/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54813, val loss: 0.55245, in 0.142s\n",
      "[331/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54811, val loss: 0.55244, in 0.141s\n",
      "[332/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54810, val loss: 0.55244, in 0.128s\n",
      "[333/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54810, val loss: 0.55244, in 0.149s\n",
      "[334/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54810, val loss: 0.55243, in 0.143s\n",
      "[335/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54809, val loss: 0.55244, in 0.127s\n",
      "[336/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54809, val loss: 0.55244, in 0.157s\n",
      "[337/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54807, val loss: 0.55241, in 0.140s\n",
      "[338/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54807, val loss: 0.55241, in 0.155s\n",
      "[339/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54806, val loss: 0.55241, in 0.149s\n",
      "[340/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54806, val loss: 0.55241, in 0.150s\n",
      "[341/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54806, val loss: 0.55240, in 0.154s\n",
      "[342/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54806, val loss: 0.55240, in 0.144s\n",
      "[343/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54805, val loss: 0.55240, in 0.141s\n",
      "[344/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54805, val loss: 0.55239, in 0.132s\n",
      "[345/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54804, val loss: 0.55239, in 0.144s\n",
      "[346/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54804, val loss: 0.55239, in 0.159s\n",
      "[347/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54804, val loss: 0.55238, in 0.175s\n",
      "[348/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54803, val loss: 0.55238, in 0.196s\n",
      "[349/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54803, val loss: 0.55238, in 0.161s\n",
      "[350/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54803, val loss: 0.55237, in 0.237s\n",
      "[351/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54803, val loss: 0.55237, in 0.146s\n",
      "[352/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54800, val loss: 0.55238, in 0.134s\n",
      "[353/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54800, val loss: 0.55238, in 0.138s\n",
      "[354/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54799, val loss: 0.55238, in 0.144s\n",
      "[355/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54799, val loss: 0.55237, in 0.137s\n",
      "[356/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54799, val loss: 0.55237, in 0.149s\n",
      "[357/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54799, val loss: 0.55237, in 0.140s\n",
      "[358/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54799, val loss: 0.55237, in 0.156s\n",
      "[359/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54798, val loss: 0.55237, in 0.169s\n",
      "[360/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54798, val loss: 0.55237, in 0.137s\n",
      "[361/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54798, val loss: 0.55237, in 0.148s\n",
      "[362/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54798, val loss: 0.55236, in 0.178s\n",
      "[363/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54798, val loss: 0.55236, in 0.150s\n",
      "[364/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54798, val loss: 0.55236, in 0.142s\n",
      "[365/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54797, val loss: 0.55235, in 0.137s\n",
      "[366/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54796, val loss: 0.55235, in 0.140s\n",
      "[367/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54795, val loss: 0.55233, in 0.197s\n",
      "[368/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54795, val loss: 0.55233, in 0.134s\n",
      "[369/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54794, val loss: 0.55233, in 0.161s\n",
      "[370/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54794, val loss: 0.55232, in 0.169s\n",
      "[371/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54793, val loss: 0.55233, in 0.142s\n",
      "[372/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54793, val loss: 0.55232, in 0.127s\n",
      "[373/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54793, val loss: 0.55232, in 0.154s\n",
      "[374/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54793, val loss: 0.55232, in 0.125s\n",
      "[375/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54792, val loss: 0.55232, in 0.137s\n",
      "[376/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54792, val loss: 0.55231, in 0.149s\n",
      "[377/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54785, val loss: 0.55226, in 0.133s\n",
      "[378/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54785, val loss: 0.55225, in 0.132s\n",
      "[379/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54785, val loss: 0.55225, in 0.142s\n",
      "[380/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54779, val loss: 0.55221, in 0.133s\n",
      "[381/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54772, val loss: 0.55216, in 0.131s\n",
      "[382/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54765, val loss: 0.55208, in 0.137s\n",
      "[383/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54760, val loss: 0.55204, in 0.133s\n",
      "[384/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54759, val loss: 0.55203, in 0.134s\n",
      "[385/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54754, val loss: 0.55200, in 0.142s\n",
      "[386/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54746, val loss: 0.55194, in 0.120s\n",
      "[387/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54741, val loss: 0.55194, in 0.114s\n",
      "[388/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54741, val loss: 0.55193, in 0.149s\n",
      "[389/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54741, val loss: 0.55193, in 0.152s\n",
      "[390/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54741, val loss: 0.55193, in 0.151s\n",
      "[391/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54741, val loss: 0.55193, in 0.149s\n",
      "[392/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54741, val loss: 0.55193, in 0.148s\n",
      "[393/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54741, val loss: 0.55193, in 0.137s\n",
      "[394/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54740, val loss: 0.55193, in 0.143s\n",
      "[395/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54740, val loss: 0.55193, in 0.146s\n",
      "[396/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54740, val loss: 0.55192, in 0.141s\n",
      "[397/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54740, val loss: 0.55192, in 0.154s\n",
      "[398/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54740, val loss: 0.55192, in 0.138s\n",
      "[399/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54740, val loss: 0.55192, in 0.145s\n",
      "[400/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54740, val loss: 0.55192, in 0.132s\n",
      "[401/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54740, val loss: 0.55192, in 0.145s\n",
      "[402/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54738, val loss: 0.55192, in 0.130s\n",
      "[403/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54738, val loss: 0.55192, in 0.152s\n",
      "[404/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54738, val loss: 0.55192, in 0.150s\n",
      "[405/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54736, val loss: 0.55192, in 0.142s\n",
      "[406/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54736, val loss: 0.55191, in 0.152s\n",
      "[407/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54735, val loss: 0.55191, in 0.116s\n",
      "[408/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54734, val loss: 0.55191, in 0.135s\n",
      "[409/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54732, val loss: 0.55189, in 0.166s\n",
      "[410/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54730, val loss: 0.55187, in 0.180s\n",
      "[411/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54730, val loss: 0.55187, in 0.190s\n",
      "[412/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54730, val loss: 0.55186, in 0.162s\n",
      "[413/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54730, val loss: 0.55186, in 0.161s\n",
      "[414/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54728, val loss: 0.55185, in 0.149s\n",
      "[415/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54725, val loss: 0.55185, in 0.122s\n",
      "[416/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54725, val loss: 0.55184, in 0.132s\n",
      "[417/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54725, val loss: 0.55184, in 0.170s\n",
      "[418/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.54724, val loss: 0.55184, in 0.181s\n",
      "[419/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54724, val loss: 0.55184, in 0.150s\n",
      "[420/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54723, val loss: 0.55183, in 0.124s\n",
      "[421/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54721, val loss: 0.55181, in 0.173s\n",
      "[422/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54721, val loss: 0.55180, in 0.181s\n",
      "[423/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54714, val loss: 0.55174, in 0.135s\n",
      "[424/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54707, val loss: 0.55167, in 0.137s\n",
      "[425/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54700, val loss: 0.55159, in 0.128s\n",
      "[426/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54696, val loss: 0.55160, in 0.132s\n",
      "[427/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54694, val loss: 0.55158, in 0.129s\n",
      "[428/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54690, val loss: 0.55155, in 0.139s\n",
      "[429/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54685, val loss: 0.55149, in 0.136s\n",
      "[430/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54682, val loss: 0.55148, in 0.142s\n",
      "[431/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.54677, val loss: 0.55141, in 0.174s\n",
      "[432/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54668, val loss: 0.55140, in 0.128s\n",
      "[433/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54661, val loss: 0.55137, in 0.121s\n",
      "[434/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54655, val loss: 0.55137, in 0.126s\n",
      "[435/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54650, val loss: 0.55132, in 0.135s\n",
      "[436/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54645, val loss: 0.55133, in 0.158s\n",
      "[437/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54638, val loss: 0.55127, in 0.144s\n",
      "[438/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54630, val loss: 0.55126, in 0.119s\n",
      "[439/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54623, val loss: 0.55122, in 0.116s\n",
      "[440/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54616, val loss: 0.55116, in 0.132s\n",
      "[441/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54610, val loss: 0.55114, in 0.136s\n",
      "[442/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54609, val loss: 0.55113, in 0.137s\n",
      "[443/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54605, val loss: 0.55110, in 0.137s\n",
      "[444/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54603, val loss: 0.55108, in 0.130s\n",
      "[445/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54603, val loss: 0.55107, in 0.138s\n",
      "[446/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54602, val loss: 0.55107, in 0.179s\n",
      "[447/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54600, val loss: 0.55105, in 0.140s\n",
      "[448/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54598, val loss: 0.55103, in 0.125s\n",
      "[449/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54596, val loss: 0.55102, in 0.134s\n",
      "[450/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54593, val loss: 0.55101, in 0.134s\n",
      "[451/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54592, val loss: 0.55102, in 0.123s\n",
      "[452/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.54587, val loss: 0.55099, in 0.206s\n",
      "[453/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54585, val loss: 0.55099, in 0.122s\n",
      "[454/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54583, val loss: 0.55098, in 0.118s\n",
      "[455/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54583, val loss: 0.55098, in 0.133s\n",
      "[456/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54583, val loss: 0.55098, in 0.142s\n",
      "[457/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54577, val loss: 0.55099, in 0.124s\n",
      "[458/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54576, val loss: 0.55098, in 0.151s\n",
      "[459/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54575, val loss: 0.55098, in 0.133s\n",
      "[460/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54574, val loss: 0.55098, in 0.141s\n",
      "[461/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54574, val loss: 0.55097, in 0.135s\n",
      "[462/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54573, val loss: 0.55097, in 0.135s\n",
      "[463/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54571, val loss: 0.55096, in 0.128s\n",
      "[464/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54570, val loss: 0.55095, in 0.133s\n",
      "[465/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54569, val loss: 0.55098, in 0.123s\n",
      "[466/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54568, val loss: 0.55097, in 0.183s\n",
      "[467/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54565, val loss: 0.55096, in 0.133s\n",
      "[468/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54564, val loss: 0.55095, in 0.142s\n",
      "[469/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54564, val loss: 0.55095, in 0.136s\n",
      "[470/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54563, val loss: 0.55094, in 0.123s\n",
      "[471/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54562, val loss: 0.55094, in 0.132s\n",
      "[472/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.54561, val loss: 0.55094, in 0.130s\n",
      "[473/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54561, val loss: 0.55094, in 0.122s\n",
      "[474/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54559, val loss: 0.55095, in 0.123s\n",
      "[475/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54558, val loss: 0.55094, in 0.124s\n",
      "[476/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.54558, val loss: 0.55094, in 0.130s\n",
      "[477/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54558, val loss: 0.55094, in 0.116s\n",
      "[478/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.54553, val loss: 0.55097, in 0.107s\n",
      "[479/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.54550, val loss: 0.55096, in 0.115s\n",
      "[480/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.54549, val loss: 0.55096, in 0.160s\n",
      "[481/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.54547, val loss: 0.55094, in 0.126s\n",
      "Fit 481 trees in 81.052 s, (14911 total leaves)\n",
      "Time spent computing histograms: 58.339s\n",
      "Time spent finding best splits:  1.321s\n",
      "Time spent applying splits:      1.655s\n",
      "Time spent predicting:           0.156s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingRegressor(loss=&#x27;absolute_error&#x27;, max_iter=1000,\n",
       "                              random_state=42, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(loss=&#x27;absolute_error&#x27;, max_iter=1000,\n",
       "                              random_state=42, verbose=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingRegressor(loss='absolute_error', max_iter=1000,\n",
       "                              random_state=42, verbose=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "# Load the Iris dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_regressor = sklearn.ensemble.HistGradientBoostingRegressor(loss=\"absolute_error\" ,random_state=42,verbose=3,max_iter=1000)\n",
    "\n",
    "# Train the Random Forest classifier on the training data\n",
    "rf_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE': 0.5380207966220709}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred=rf_regressor.predict(X_test)\n",
    "print(evaluate_estimator(rf_regressor,X_test,y_test))\n",
    "plot_residuals(rf_regressor,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.drop([\"pair\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"vendor_id\"]=test[\"vendor_id\"].map(str)\n",
    "test=pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.reindex(X.columns, axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.Series(rf_regressor.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"result.txt\",sep=\"\\t\", index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "train_sizes, train_scores, valid_scores=learning_curve(estimator=rf_regressor,X=x_train,y=y_train)\n",
    "plt.plot(train_sizes,train_scores),plt.plot(train_sizes,valid_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
